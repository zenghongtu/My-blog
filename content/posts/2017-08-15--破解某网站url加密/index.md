---
title: ç ´è§£æŸç½‘ç«™urlåŠ å¯†
category: "çˆ¬è™«"
cover: cat2.jpg
author: Jason Zeng
---

æƒ³è¦çˆ¬å–ç½‘ç«™http://dir.scmor.com/google/ ä¸­Googleé•œåƒç«™çš„é“¾æ¥ï¼Œä¸€çœ¼çœ‹å»è¿˜ä»¥ä¸ºç®€å•æå–ä¸€ä¸‹hrefå°±å¥½ï¼Œä»”ç»†çœ‹çœ‹å¥½åƒæ²¡é‚£ä¹ˆç®€å•ã€‚

1. åˆ†æ

ç½‘é¡µæºç å¦‚ä¸‹ï¼Œç‚¹å‡»ç°åœ¨è®¿é—®æ‰§è¡Œvisitå‡½æ•°ï¼Œä¼ å…¥çš„å­—ç¬¦ä¸²ä¸ºbase64ç¼–ç ã€‚
```html
< a href="javascript:;" class="ok" onclick="visit('DSE8WyM3DBsjQGsWNj5YXSEsEgovACEETDBXUA==')"> ç°åœ¨è®¿é—® </a>
```
ç›´æ¥å°†è¯¥å­—ç¬¦ä¸²base64è§£ç å¾—åˆ°ç»“æœå¦‚ä¸‹ã€‚ä¹±ç ï¼Œè¯´æ˜ä¸æ˜¯ç®€å•çš„å°†urlç»è¿‡base64ç¼–ç ã€‚
```bash
!<[#7#@k6>X]!,
/!L0WP
```
é€šè¿‡æŸ¥æ‰¾jsæ–‡ä»¶ï¼Œæ‰¾åˆ°visitå‡½æ•°
```js
function visit(url) {
    var newTab = window.open('about:blank');
    if (Gword != '') url = strdecode(url);
    // var newTab = window.open(url);
    newTab.location.href = url;
    //newTab.location.reload(true);
}
```
é€šè¿‡javascriptæºç å¯ä»¥çœ‹å‡ºï¼Œå°†å­—ç¬¦ä¸²ç»è¿‡strdecodeå‡½æ•°å¤„ç†åï¼Œå³å¯å¾—åˆ°çœŸå®çš„urlã€‚
strdecodeå‡½æ•°ä»£ç å¦‚ä¸‹
```js
function strdecode(string) {
    string = base64decode(string);
    key = Gword;
    len = key.length;
    code = '';
    for (i = 0; i < string.length; i++) {
        var k = i % len;
        code += String.fromCharCode(string.charCodeAt(i) ^ key.charCodeAt(k))
    }
    return base64decode(code)
}
```
é€šè¿‡æŸ¥æ‰¾ï¼ŒGwordçš„å€¼ä¸ºlink@scmor.comã€‚è‡³æ­¤ï¼Œå·²ç»äº†è§£äº†ç½‘å€åŠ å¯†è§£å¯†çš„æ•´ä¸ªè¿‡ç¨‹ï¼Œå¯ä»¥å¼€å§‹ç¼–å†™ä»£ç å•¦ã€‚

2. Coding

```python
import requests
import base64
import re
import time

headers = {
    'User-Agent': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:39.0) Gecko/20100101 Firefox/39.0',
    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
    'Accept-Language': 'en-US,en;q=0.5',
    'Accept-Encoding': 'gzip, deflate',
    'Connection': 'keep-alive'}

def get_encoded_urls():
    html=requests.get('http://dir.scmor.com/google/',headers=headers).text.replace('\r','').replace('
','').replace(' ','')
    encoded_urls=re.findall('autourl\[\d+\]="(.*?)";',html)
    return encoded_urls

def from_char_code(a, *b):
    try:
        return unichr(a%65536) + ''.join([unichr(i%65536) for i in b])
    except:
        return chr(a%65536) + ''.join([chr(i%65536) for i in b])

def decode(string):
    string=base64.b64decode(string).decode('utf-8')
    key='link@scmor.com'
    length=len(key)
    code=''
    for i in range(len(string)):
        k=i%length
        code+=from_char_code(ord(string[i])^ord(key[k]))
    result=base64.b64decode(code).decode('utf-8')
    return result

def write_to_txt(urls):
    f=open('result.txt','w')
    for url in urls:
        f.write(url+'
')
    f.close()

def crawl():
    encoded_urls=get_encoded_urls()
    urls=[]
    for string in encoded_urls:
        url=decode(string)
        urls.append(url)
    write_to_txt(urls)

crawl()
```
